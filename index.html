<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mediabunny Caption Burner - Final Prototype</title>
    <style>
        * { box-sizing: border-box; }
        body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 2rem auto; background: #0f172a; padding: 0 1rem; color: #e2e8f0; }
        .box { background: #1e293b; padding: 2.5rem; border-radius: 12px; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.5); text-align: center; border: 1px solid #334155; }
        .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 2rem; }
        video { width: 100%; border-radius: 8px; background: #000; border: 1px solid #334155; aspect-ratio: 16/9; }
        button { background: #2563eb; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1rem; font-weight: 600; transition: all 0.2s; }
        button:hover { background: #1d4ed8; transform: translateY(-1px); }
        button:disabled { background: #475569; cursor: not-allowed; }
        input[type="text"], input[type="file"] { padding: 10px; width: 70%; margin: 15px 0; border: 1px solid #475569; border-radius: 6px; font-size: 1rem; text-align: center; background: #0f172a; color: #e2e8f0; }
        input[type="text"]:focus, input[type="file"]:focus { outline: none; border-color: #2563eb; box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.1); }
        #status { margin-top: 1.5rem; font-weight: 600; color: #94a3b8; min-height: 1.5em; }
        .loading-overlay { position: fixed; top:0; left:0; width:100%; height:100%; background: #0f172a; display: flex; justify-content: center; align-items: center; z-index: 100; flex-direction: column; }

        /* Tabs styling */
        .tabs-container { display: flex; gap: 0.5rem; margin-bottom: 2rem; border-bottom: 2px solid #334155; }
        .tab { padding: 12px 24px; background: none; border: none; cursor: pointer; color: #94a3b8; font-size: 1rem; font-weight: 600; border-bottom: 3px solid transparent; transition: all 0.2s; }
        .tab:hover { color: #cbd5e1; }
        .tab.active { color: #2563eb; border-bottom-color: #2563eb; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }

        h1 { margin-top: 0; color: #f1f5f9; }
        p { color: #cbd5e1; }
        .info-text { font-size: 0.9rem; color: #94a3b8; margin: 0.5rem 0; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/hls.js@latest/dist/hls.min.js"></script>
</head>
<body>

    <div id="libLoading" class="loading-overlay">
        <h3>Loading Mediabunny...</h3>
        <p>Fetching modern media libraries from CDN</p>
    </div>

    <div class="box">
        <h1>üî• Video Caption Burner</h1>
        <p>Burn captions onto your videos. Works with files and HLS streams. Everything processes locally in your browser.</p>

        <div class="tabs-container">
            <button class="tab active" data-tab="file-tab">üìÅ Upload Video</button>
            <button class="tab" data-tab="hls-tab">üåê HLS Stream</button>
        </div>

        <div id="file-tab" class="tab-content active">
            <p class="info-text">Select an MP4 or WebM video file from your device</p>
            <input type="file" id="fileInput" accept="video/mp4,video/webm" /><br>
        </div>

        <div id="hls-tab" class="tab-content">
            <p class="info-text">Paste an HLS stream URL (must end with .m3u8)</p>
            <div style="display: flex; gap: 0.5rem; align-items: center; justify-content: center; margin: 15px 0;">
                <input type="text" id="hlsUrlInput" value="https://test-streams.mux.dev/x36xhzz/x36xhzz.m3u8" placeholder="https://example.com/video.m3u8" style="width: 50%; margin: 0;" />
                <button id="hlsLoadBtn" style="padding: 10px 20px; margin: 0;">Load</button>
            </div>
        </div>

        <input type="text" id="captionText" value="CAPTION" placeholder="Enter caption text"><br>
        <button id="processBtn" disabled>‚ö° Process & Burn Captions</button>
        <div id="status">Select a video to get started</div>
    </div>

    <div class="grid">
        <div>
            <h4>Original</h4>
            <video id="originalVideo" controls muted></video>
        </div>
        <div>
            <h4>Burned Result</h4>
            <video id="outputVideo" controls></video>
        </div>
    </div>

    <div id="shareButtons" style="display:none; text-align: center; margin-top: 2rem; gap: 1rem;">
        <button id="downloadBtn" style="background: #25d366; margin: 0 0.5rem;">‚¨áÔ∏è Download Video</button>
        <button id="whatsappBtn" style="background: #25d366; margin: 0 0.5rem;">üí¨ Share to WhatsApp</button>
    </div>

    <canvas id="canvas" style="display:none;"></canvas>

    <script type="module">
        import { 
            Input, 
            Output, 
            BlobSource, 
            BufferTarget, 
            Mp4OutputFormat, 
            CanvasSource,
            VideoSampleSink,
            MediaStreamAudioTrackSource,
            ALL_FORMATS 
        } from 'https://esm.sh/mediabunny@1.25.8';

        // Remove loading screen once imports are ready
        document.getElementById('libLoading').style.display = 'none';

        const fileInput = document.getElementById('fileInput');
        const hlsUrlInput = document.getElementById('hlsUrlInput');
        const hlsLoadBtn = document.getElementById('hlsLoadBtn');
        const processBtn = document.getElementById('processBtn');
        const status = document.getElementById('status');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d', { alpha: false });
        const downloadBtn = document.getElementById('downloadBtn');
        const whatsappBtn = document.getElementById('whatsappBtn');
        const shareButtons = document.getElementById('shareButtons');

        let selectedFile = null;
        let hlsUrl = null;
        let sourceType = null; // 'file' or 'hls'
        let hlsInstance = null;
        let outputBlob = null;

        // Tab switching functionality
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                // Remove active class from all tabs and contents
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));

                // Add active class to clicked tab
                tab.classList.add('active');

                // Show corresponding content
                const tabId = tab.getAttribute('data-tab');
                document.getElementById(tabId).classList.add('active');

                // Clear the other input
                if (tabId === 'file-tab') {
                    hlsUrlInput.value = '';
                    hlsUrl = null;
                } else {
                    fileInput.value = '';
                    selectedFile = null;
                }
            });
        });

        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length) {
                selectedFile = e.target.files[0];
                hlsUrl = null; // Clear HLS URL when file is selected
                hlsUrlInput.value = ''; // Clear HLS input field
                sourceType = 'file';

                // Cleanup HLS instance if it exists
                if (hlsInstance) {
                    hlsInstance.destroy();
                    hlsInstance = null;
                }

                document.getElementById('originalVideo').src = URL.createObjectURL(selectedFile);
                processBtn.disabled = false;
                status.textContent = "Ready to process: " + selectedFile.name;
                console.log("File selected:", selectedFile.name);
            }
        });

        // Helper to load HLS URL
        async function loadHlsUrl(url) {
            url = url.trim();
            if (url) {
                // Validate URL format
                if (!url.match(/^https?:\/\/.+\.m3u8$/i)) {
                    status.textContent = "Invalid URL. Please provide a valid HLS stream URL ending with .m3u8";
                    hlsUrlInput.value = '';
                    processBtn.disabled = true;
                    return;
                }

                selectedFile = null; // Clear file when URL is entered
                fileInput.value = ''; // Clear file input field
                hlsUrl = url;
                sourceType = 'hls';

                status.textContent = "Loading HLS stream...";
                processBtn.disabled = true;

                try {
                    await loadHlsPreview(url);
                    processBtn.disabled = false;
                    status.textContent = "Ready to process: " + url;
                    console.log("HLS URL loaded:", url);
                } catch (err) {
                    console.error("HLS loading error:", err);
                    status.textContent = "Error loading HLS stream: " + err.message;
                    hlsUrl = null;
                    hlsUrlInput.value = '';
                    processBtn.disabled = true;
                }
            } else {
                selectedFile = null;
                hlsUrl = null;
                sourceType = null;
                processBtn.disabled = true;
                status.textContent = "Please select an MP4 file or HLS stream URL.";
            }
        }

        hlsUrlInput.addEventListener('change', async (e) => {
            await loadHlsUrl(e.target.value);
        });

        hlsLoadBtn.addEventListener('click', async () => {
            await loadHlsUrl(hlsUrlInput.value);
        });

        processBtn.addEventListener('click', async () => {
            processBtn.disabled = true;
            status.textContent = "Processing... do not close this tab.";

            console.log("=== PIPELINE START ===");
            try {
                const source = sourceType === 'file' ? selectedFile : hlsUrl;
                await runPipeline(sourceType, source, document.getElementById('captionText').value);
                console.log("=== PIPELINE SUCCESS ===");
            } catch (err) {
                console.error("=== PIPELINE ERROR ===", err);
                console.error("Error message:", err.message);
                console.error("Error stack:", err.stack);
                status.textContent = "Error: " + err.message;
                processBtn.disabled = false;
            }
        });

        // HLS helper function to load preview video
        async function loadHlsPreview(url) {
            const previewVideo = document.getElementById('originalVideo');

            // Check for native HLS support (Safari)
            if (previewVideo.canPlayType('application/vnd.apple.mpegurl')) {
                previewVideo.src = url;
                return new Promise((resolve) => {
                    previewVideo.addEventListener('loadedmetadata', resolve, { once: true });
                });
            }

            // Use hls.js for other browsers
            if (!window.Hls) {
                throw new Error('HLS.js library failed to load');
            }

            // Create new HLS instance for preview
            const tempHls = new Hls();
            tempHls.attachMedia(previewVideo);
            tempHls.loadSource(url);

            return new Promise((resolve, reject) => {
                tempHls.on(Hls.Events.MANIFEST_PARSED, () => {
                    resolve();
                });
                tempHls.on(Hls.Events.ERROR, (event, data) => {
                    tempHls.destroy();
                    reject(new Error(`HLS Error: ${data.type} - ${data.reason}`));
                });
            });
        }

        // HLS helper function to load source for processing
        async function loadHlsSource(url, videoElement) {
            // Check for native HLS support (Safari)
            if (videoElement.canPlayType('application/vnd.apple.mpegurl')) {
                videoElement.src = url;
                return new Promise((resolve, reject) => {
                    const timeout = setTimeout(() => reject(new Error('Metadata loading timeout')), 30000);
                    videoElement.addEventListener('loadedmetadata', () => {
                        clearTimeout(timeout);
                        resolve({
                            displayWidth: videoElement.videoWidth,
                            displayHeight: videoElement.videoHeight,
                            duration: videoElement.duration,
                            hlsInstance: null
                        });
                    }, { once: true });
                    videoElement.addEventListener('error', () => {
                        clearTimeout(timeout);
                        reject(videoElement.error);
                    }, { once: true });
                });
            }

            // Use hls.js for other browsers
            if (!window.Hls) {
                throw new Error('HLS.js library failed to load');
            }

            const hls = new Hls({
                enableWorker: true,
                lowLatencyMode: false
            });

            hls.attachMedia(videoElement);
            hls.loadSource(url);

            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    hls.destroy();
                    reject(new Error('HLS manifest loading timeout'));
                }, 30000);

                hls.on(Hls.Events.MANIFEST_PARSED, () => {
                    clearTimeout(timeout);
                    // Store instance for cleanup
                    hlsInstance = hls;
                    resolve({
                        displayWidth: videoElement.videoWidth,
                        displayHeight: videoElement.videoHeight,
                        duration: videoElement.duration,
                        hlsInstance: hls
                    });
                });

                hls.on(Hls.Events.ERROR, (event, data) => {
                    clearTimeout(timeout);
                    hls.destroy();
                    reject(new Error(`HLS Error: ${data.type} - ${data.reason}`));
                });
            });
        }

        // Helper function to wait for video metadata and get actual duration
        async function getVideoMetadata(videoElement) {
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('Video metadata loading timeout'));
                }, 10000);

                const onLoadedMetadata = () => {
                    clearTimeout(timeout);
                    videoElement.removeEventListener('loadedmetadata', onLoadedMetadata);
                    videoElement.removeEventListener('error', onError);

                    const actualDuration = videoElement.duration;
                    console.log("Video metadata loaded - duration:", actualDuration);

                    resolve({
                        width: videoElement.videoWidth,
                        height: videoElement.videoHeight,
                        duration: actualDuration
                    });
                };

                const onError = () => {
                    clearTimeout(timeout);
                    videoElement.removeEventListener('loadedmetadata', onLoadedMetadata);
                    videoElement.removeEventListener('error', onError);
                    reject(videoElement.error || new Error('Video loading error'));
                };

                videoElement.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });
                videoElement.addEventListener('error', onError, { once: true });
            });
        }

        async function runPipeline(sourceType, source, textToBurn) {
            // 1. Load metadata based on source type
            let displayWidth, displayHeight, duration, frameRate;
            let currentHlsInstance = null;
            let input = null; // Keep reference for audio extraction
            let audioTrack = null; // Audio track reference

            const tempVideo = document.createElement('video');
            tempVideo.crossOrigin = 'anonymous';

            if (sourceType === 'file') {
                // File-based source: Use Mediabunny for format info, video element for accurate duration
                console.log("Loading file source...");
                input = new Input({
                    source: new BlobSource(source),
                    formats: ALL_FORMATS
                });

                const videoTrack = await input.getPrimaryVideoTrack();
                displayWidth = videoTrack.displayWidth;
                displayHeight = videoTrack.displayHeight;
                frameRate = videoTrack.frameRate || 30; // Use actual FPS from video track

                // Try to get audio track
                try {
                    audioTrack = await input.getPrimaryAudioTrack();
                    if (audioTrack) {
                        console.log("Audio track found - sample rate:", audioTrack.sampleRate, "channels:", audioTrack.channels);
                    }
                } catch (err) {
                    console.warn("No audio track found:", err);
                }

                // Setup temp video for file
                tempVideo.src = URL.createObjectURL(source);

                // Wait for actual video metadata to get accurate duration
                try {
                    const videoMeta = await getVideoMetadata(tempVideo);
                    duration = videoMeta.duration;
                    console.log("Got actual video duration from element:", duration);
                } catch (err) {
                    console.warn("Failed to get duration from video element, using Mediabunny duration:", err);
                    duration = videoTrack.duration || 10;
                }
            } else if (sourceType === 'hls') {
                // HLS source: Load directly
                console.log("Loading HLS source...");
                const metadata = await loadHlsSource(source, tempVideo);
                displayWidth = metadata.displayWidth;
                displayHeight = metadata.displayHeight;
                duration = metadata.duration || 10;
                frameRate = 30; // HLS doesn't have reliable FPS detection, default to 30
                currentHlsInstance = metadata.hlsInstance;

                // Double-check duration from video element
                if (!isFinite(duration) || duration <= 0) {
                    console.warn("Invalid duration from HLS metadata, getting from video element");
                    try {
                        const videoMeta = await getVideoMetadata(tempVideo);
                        duration = videoMeta.duration;
                    } catch (err) {
                        console.error("Failed to get duration:", err);
                        duration = 10;
                    }
                }

                // SETUP HLS AUDIO
                // We capture the stream from the video element to get the audio track
                try {
                    console.log("Capturing stream from video element for audio...");
                    // captureStream() might be experimental in some browsers or require 'mozCaptureStream'
                    const stream = tempVideo.captureStream ? tempVideo.captureStream() : tempVideo.mozCaptureStream();
                    
                    if (stream) {
                        const nativeAudioTrack = stream.getAudioTracks()[0];
                        if (nativeAudioTrack) {
                            // Use MediaStreamAudioTrackSource to encode the real-time audio
                            // We attempt to use AAC (mp4a.40.2) for MP4 compatibility, though browser support varies.
                            // If this fails, we might need to fallback to Opus and WebM container.
                            audioTrack = new MediaStreamAudioTrackSource(nativeAudioTrack);
                            console.log("Captured HLS audio track via MediaStreamAudioTrackSource");
                        } else {
                            console.warn("Stream captured but no audio track found.");
                        }
                    } else {
                        console.warn("captureStream not supported, HLS will be silent.");
                    }
                } catch (err) {
                    console.warn("Failed to capture HLS stream:", err);
                }

            } else {
                throw new Error('Unknown source type: ' + sourceType);
            }

            // Cap output duration at 30 seconds
            const MAX_OUTPUT_DURATION = 30;
            if (duration > MAX_OUTPUT_DURATION) {
                console.log(`Duration limited: ${duration.toFixed(2)}s ‚Üí ${MAX_OUTPUT_DURATION}s`);
                duration = MAX_OUTPUT_DURATION;
            }

            console.log("Video metadata:", { sourceType, displayWidth, displayHeight, duration: duration.toFixed(2) + 's', frameRate: frameRate + ' FPS' });

            // 2. Setup Canvas based on video dimensions
            canvas.width = displayWidth;
            canvas.height = displayHeight;

            // Helper function for drawing
            function drawFrameAndBurn(vid, text, w, h) {
                // Draw video frame to canvas
                ctx.drawImage(vid, 0, 0, w, h);

                // Draw Caption Text Overlay with adaptive positioning
                const aspectRatio = w / h;
                const isVertical = aspectRatio < 1;

                const fontSize = isVertical ? h * 0.06 : h * 0.08;
                ctx.font = `bold ${Math.floor(fontSize)}px sans-serif`;
                ctx.fillStyle = '#ffffff';
                ctx.strokeStyle = '#000000';
                ctx.lineWidth = Math.max(2, h * 0.005);
                ctx.textAlign = 'center';

                const x = w / 2;
                const y = isVertical ? h - (h * 0.3) : h - (h * 0.1);

                ctx.strokeText(text, x, y);
                ctx.fillText(text, x, y);
            }

            // 4. Setup Mediabunny Output (Writer/Muxer)
            const output = new Output({
                target: new BufferTarget(),
                format: new Mp4OutputFormat()
            });

            // 5. Setup Video Source (The Encoder that watches the Canvas)
            const videoSource = new CanvasSource(canvas, {
                codec: 'avc',
                bitrate: 6_000_000 // 6 Mbps for high-quality text
            });
            output.addVideoTrack(videoSource, { frameRate });

            // 6. Add audio track if available
            let audioSource = null;
            if (audioTrack) {
                try {
                    console.log("Adding audio track to output...");
                    // For now, we'll attempt to copy audio from the input
                    // This creates an audio source that will be filled during processing
                    audioSource = audioTrack;
                    output.addAudioTrack(audioTrack);
                    console.log("‚úì Audio track added to output");
                } catch (err) {
                    console.warn("Failed to add audio track:", err);
                    audioSource = null;
                }
            }

            await output.start();

            console.log("=== STARTING VIDEO ENCODING ===");

            // 7. Processing Loop (Dual Strategy)
            let frameCount = 0;
            const totalFrames = Math.ceil(duration * frameRate);

            if (sourceType === 'file') {
                // STRATEGY A: Seek-and-Snapshot (Fastest for files)
                // Files allow random access, so we can seek efficiently.
                console.log(`Using 'Seek-and-Snapshot' strategy for File. ~${totalFrames} frames.`);
                
                const frameDuration = 1 / frameRate;

                for (let f = 0; f < totalFrames; f++) {
                    try {
                        // Seek to frame time
                        const frameTime = f / frameRate;
                        tempVideo.currentTime = frameTime;

                        // Wait for frame to be seeked
                        await new Promise((resolve) => {
                            const checkReady = () => {
                                if (Math.abs(tempVideo.currentTime - frameTime) < 0.001) {
                                    tempVideo.removeEventListener('seeked', checkReady);
                                    resolve();
                                }
                            };
                            tempVideo.addEventListener('seeked', checkReady, { once: true });
                            // Fallback timeout in case seek doesn't fire
                            setTimeout(resolve, 50);
                        });

                        // Draw and Burn
                        drawFrameAndBurn(tempVideo, textToBurn, displayWidth, displayHeight);

                        // Add frame to encoder
                        await videoSource.add(frameTime, frameDuration);
                        frameCount++;

                        if (frameCount % 30 === 0) {
                            status.textContent = `Processing: ${frameCount} / ${totalFrames} frames...`;
                        }
                    } catch (err) {
                        console.error(`Error processing frame ${f}:`, err);
                        throw err;
                    }
                }
            } else {
                // STRATEGY B: Real-time Play-Through (Required for HLS)
                // HLS seeking is inaccurate (skipping). We must play it to get smooth video + audio.
                console.log("Using 'Play-Through' strategy for HLS (captures playback).");
                
                // Mute the video element so the user doesn't hear the fast playback process
                tempVideo.muted = false; // Must be false to capture audio? No, captureStream captures even if muted, usually. 
                // However, Chrome sometimes mutes captureStream if element is muted. 
                // Let's keep it muted but cross fingers, or use volume=0.
                tempVideo.volume = 0.0; 
                
                // Try to handle audio for HLS
                // We need to feed audio data to mediabunny. 
                // Since we added the track from the MediaStream (captureStream) earlier, 
                // we just need to let the video play. The MediaStreamTrack we passed to output
                // should automatically pipe data as long as the source is active.

                // Setup frame capture loop
                await new Promise((resolve, reject) => {
                    let processing = true;
                    
                    const processFrame = async (now, metadata) => {
                        if (!processing) return;
                        
                        try {
                            // Check if we are done
                            if (tempVideo.ended || tempVideo.currentTime >= duration) {
                                console.log("HLS Playback finished or duration reached.");
                                processing = false;
                                tempVideo.pause();
                                resolve();
                                return;
                            }

                            // Draw and Burn
                            drawFrameAndBurn(tempVideo, textToBurn, displayWidth, displayHeight);

                            // Add frame to encoder
                            // Use metadata.mediaTime for accurate sync
                            const timestamp = metadata.mediaTime;
                            const duration = 1 / frameRate; // Best guess for duration
                            
                            await videoSource.add(timestamp, duration);
                            frameCount++;
                            
                            if (frameCount % 30 === 0) {
                                status.textContent = `Recording HLS: ${frameCount} frames...`;
                            }

                            // Continue loop
                            tempVideo.requestVideoFrameCallback(processFrame);
                        } catch (e) {
                            processing = false;
                            reject(e);
                        }
                    };

                    // Start playback
                    tempVideo.requestVideoFrameCallback(processFrame);
                    tempVideo.play().catch(e => {
                        console.error("Auto-play failed:", e);
                        reject(e);
                    });
                });
            }

            console.log("=== FRAME LOOP COMPLETE ===");
            console.log("Total frames encoded:", frameCount);

            // Close the video source to signal end of stream
            console.log("Closing video source...");
            await videoSource.close();
            console.log("‚úì Video source closed");

            // 8. Finalize and Export
            status.textContent = "Finalizing MP4 file...";
            console.log("Calling output.finalize()...");
            await output.finalize();
            console.log("‚úì output.finalize() complete");

            // Debug: Check what's in the buffer
            console.log("=== OUTPUT BUFFER DEBUG ===");
            console.log("output.target:", output.target);
            console.log("output.target.buffer:", output.target.buffer);
            console.log("Buffer type:", output.target.buffer?.constructor?.name);
            console.log("Buffer byteLength:", output.target.buffer?.byteLength);
            console.log("Buffer length:", output.target.buffer?.length);

            let finalBlob;
            if (output.target.buffer instanceof ArrayBuffer) {
                console.log("Buffer is ArrayBuffer - creating Uint8Array wrapper");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else if (output.target.buffer instanceof Uint8Array) {
                console.log("Buffer is Uint8Array - using directly");
                finalBlob = new Blob([output.target.buffer], { type: 'video/mp4' });
            } else if (Array.isArray(output.target.buffer)) {
                console.log("Buffer is Array - converting to Uint8Array");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else {
                const bufferType = typeof output.target.buffer;
                console.error("Unknown buffer type:", bufferType);
                throw new Error(`Unexpected buffer type: ${bufferType}`);
            }

            console.log("‚úì Final blob created - size:", finalBlob.size, "bytes");

            if (finalBlob.size < 200) {
                console.warn("‚ö†Ô∏è  Blob is very small (likely just MP4 header, no video data encoded)");
            }

            const videoUrl = URL.createObjectURL(finalBlob);
            document.getElementById('outputVideo').src = videoUrl;
            console.log("‚úì Output video src set");

            // Store blob for sharing and downloading
            outputBlob = finalBlob;
            shareButtons.style.display = 'flex';

            status.textContent = "Success! Video generated locally. Share or download below.";
            processBtn.disabled = false;

            // Cleanup HLS instance if used
            if (currentHlsInstance) {
                console.log("Cleaning up HLS instance...");
                currentHlsInstance.destroy();
                hlsInstance = null;
            }

            console.log("=== PIPELINE COMPLETE ===");
        }

        // Download button handler
        downloadBtn.addEventListener('click', () => {
            if (!outputBlob) return;
            const url = URL.createObjectURL(outputBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `caption-burn-${new Date().getTime()}.mp4`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            console.log("‚úì Video downloaded");
        });

        // WhatsApp share button handler
        whatsappBtn.addEventListener('click', async () => {
            if (!outputBlob) return;

            const videoFile = new File([outputBlob], 'caption-burn-video.mp4', { type: 'video/mp4' });

            // Check if Web Share API is available (for mobile)
            if (navigator.share && navigator.canShare) {
                try {
                    // Test if files can be shared
                    if (navigator.canShare({ files: [videoFile] })) {
                        await navigator.share({
                            files: [videoFile],
                            title: 'Caption Burned Video',
                            text: 'Check out this video with burned-in captions!'
                        });
                        console.log("‚úì Shared via Web Share API");
                        status.textContent = "Video shared to WhatsApp!";
                    } else {
                        // Files not supported, use text-only fallback
                        throw new Error('File sharing not supported');
                    }
                } catch (err) {
                    console.log("Web Share API not available or failed, using WhatsApp Web fallback");
                    // Fallback: Open WhatsApp Web with a message
                    const text = "Check out this video with burned-in captions! Generated with Caption Burner üî•";
                    const whatsappUrl = `https://wa.me/?text=${encodeURIComponent(text)}`;
                    window.open(whatsappUrl, '_blank');
                    console.log("‚úì Opened WhatsApp Web");
                    status.textContent = "WhatsApp Web opened! Download the video and attach it to your message.";
                }
            } else {
                // Fallback: Open WhatsApp Web with a message
                const text = "Check out this video with burned-in captions! Generated with Caption Burner üî•";
                const whatsappUrl = `https://wa.me/?text=${encodeURIComponent(text)}`;
                window.open(whatsappUrl, '_blank');
                console.log("‚úì Opened WhatsApp Web");

                // Show instructions
                status.textContent = "WhatsApp Web opened! Download the video and attach it to your message.";
            }
        });
    </script>
</body>
</html>