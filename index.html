<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mediabunny Caption Burner - Final Prototype</title>
    <style>
        body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 2rem auto; background: #f8fafc; padding: 0 1rem; color: #1e293b; }
        .box { background: white; padding: 2.5rem; border-radius: 12px; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1); text-align: center; }
        .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 2rem; }
        video { width: 100%; border-radius: 8px; background: #000; border: 1px solid #e2e8f0; aspect-ratio: 16/9; }
        button { background: #2563eb; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1rem; font-weight: 600; transition: background 0.2s; }
        button:hover { background: #1d4ed8; }
        button:disabled { background: #94a3b8; cursor: not-allowed; }
        input[type="text"] { padding: 10px; width: 70%; margin: 15px 0; border: 1px solid #cbd5e1; border-radius: 6px; font-size: 1rem; text-align: center; }
        #status { margin-top: 1.5rem; font-weight: 600; color: #475569; min-height: 1.5em; }
        .loading-overlay { position: fixed; top:0; left:0; width:100%; height:100%; background: white; display: flex; justify-content: center; align-items: center; z-index: 100; flex-direction: column; }
    </style>
</head>
<body>

    <div id="libLoading" class="loading-overlay">
        <h3>Loading Mediabunny...</h3>
        <p>Fetching modern media libraries from CDN</p>
    </div>

    <div class="box">
        <h1>Video Caption Burner</h1>
        <p>Processes everything locally in your browser using WebCodecs.</p>
        
        <input type="file" id="fileInput" accept="video/mp4,video/webm" /><br>
        <input type="text" id="captionText" value="CLIENT PREVIEW - JANUARY 2026" placeholder="Enter text to burn"><br>
        <button id="processBtn" disabled>Process & Burn Captions</button>
        <div id="status">Please select an MP4 file.</div>
    </div>

    <div class="grid">
        <div>
            <h4>Original</h4>
            <video id="originalVideo" controls muted></video>
        </div>
        <div>
            <h4>Burned Result</h4>
            <video id="outputVideo" controls></video>
        </div>
    </div>

    <canvas id="canvas" style="display:none;"></canvas>

    <script type="module">
        import { 
            Input, 
            Output, 
            BlobSource, 
            BufferTarget, 
            Mp4OutputFormat, 
            CanvasSource,
            VideoSampleSink,
            ALL_FORMATS 
        } from 'https://esm.sh/mediabunny@1.25.8';

        // Remove loading screen once imports are ready
        document.getElementById('libLoading').style.display = 'none';

        const fileInput = document.getElementById('fileInput');
        const processBtn = document.getElementById('processBtn');
        const status = document.getElementById('status');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d', { alpha: false });

        let selectedFile = null;

        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length) {
                selectedFile = e.target.files[0];
                document.getElementById('originalVideo').src = URL.createObjectURL(selectedFile);
                processBtn.disabled = false;
                status.textContent = "Ready to process: " + selectedFile.name;
            }
        });

        processBtn.addEventListener('click', async () => {
            processBtn.disabled = true;
            status.textContent = "Processing... do not close this tab.";

            console.log("=== PIPELINE START ===");
            try {
                await runPipeline(selectedFile, document.getElementById('captionText').value);
                console.log("=== PIPELINE SUCCESS ===");
            } catch (err) {
                console.error("=== PIPELINE ERROR ===", err);
                console.error("Error message:", err.message);
                console.error("Error stack:", err.stack);
                status.textContent = "Error: " + err.message;
                processBtn.disabled = false;
            }
        });

        async function runPipeline(file, textToBurn) {
            // 1. Initialize Mediabunny Input
            const input = new Input({
                source: new BlobSource(file),
                formats: ALL_FORMATS
            });
            
            const videoTrack = await input.getPrimaryVideoTrack();
            const { displayWidth, displayHeight } = videoTrack;

            // 2. Setup Canvas based on video dimensions
            canvas.width = displayWidth;
            canvas.height = displayHeight;

            // 3. Setup Mediabunny Output (Writer/Muxer)
            const output = new Output({
                target: new BufferTarget(),
                format: new Mp4OutputFormat()
            });

            // 4. Setup Video Source (The Encoder that watches the Canvas)
            const videoSource = new CanvasSource(canvas, {
                codec: 'avc',
                bitrate: 6_000_000 // 6 Mbps for high-quality text
            });
            output.addVideoTrack(videoSource, { frameRate: 30 });
            await output.start();

            // 5. Setup Sink to pull decoded frames
            const sink = new VideoSampleSink(videoTrack);
            let frameCount = 0;
            let sampleCount = 0;

            console.log("=== STARTING FRAME LOOP ===");
            console.log("Canvas size:", canvas.width, "x", canvas.height);
            console.log("VideoSampleSink:", sink);
            console.log("CanvasSource methods:", Object.getOwnPropertyNames(Object.getPrototypeOf(videoSource)).filter(m => !m.startsWith('_')));

            //
            // This loop pulls samples one by one from the file
            for await (const sample of sink.samples()) {
                sampleCount++;
                const frame = sample.data;

                if (sampleCount <= 3) {
                    console.log(`Sample ${sampleCount}:`, { timestamp: sample.timestamp, duration: sample.duration });
                }

                // Ensure the sample data is a valid VideoFrame
                if (frame instanceof VideoFrame) {
                    // A. Draw video frame to our processing canvas
                    ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);

                    // B. Draw Caption Text Overlay
                    // Font size scales with video height (8% of height)
                    ctx.font = `bold ${Math.floor(canvas.height * 0.08)}px sans-serif`;
                    ctx.fillStyle = '#ffffff';
                    ctx.strokeStyle = '#000000';
                    ctx.lineWidth = Math.max(2, canvas.height * 0.005);
                    ctx.textAlign = 'center';

                    const x = canvas.width / 2;
                    const y = canvas.height - (canvas.height * 0.1); // 10% from bottom

                    ctx.strokeText(textToBurn, x, y);
                    ctx.fillText(textToBurn, x, y);

                    // C. Feed the canvas into the output encoder
                    // CanvasSource.add(timestamp, duration) - timestamps in seconds
                    const timestampSec = sample.timestamp / 1_000_000; // microseconds to seconds
                    const frameDuration = (sample.duration || 33333) / 1_000_000; // use sample duration or default to 30fps

                    try {
                        await videoSource.add(timestampSec, frameDuration);
                        if (sampleCount === 1) {
                            console.log("✓ First frame added successfully");
                        }
                    } catch (addErr) {
                        console.error(`✗ Error adding frame ${sampleCount}:`, addErr);
                        throw addErr;
                    }

                    // D. CRITICAL: Free GPU memory
                    frame.close();
                    frameCount++;
                } else {
                    console.warn(`Sample ${sampleCount} is not a VideoFrame:`, frame?.constructor?.name);
                }

                if (frameCount > 0 && frameCount % 30 === 0) {
                    status.textContent = `Processing: ${frameCount} frames completed...`;
                }
            }

            console.log("=== FRAME LOOP COMPLETE ===");
            console.log("Total samples:", sampleCount, "Total frames encoded:", frameCount);

            // Close the video source to signal end of stream
            console.log("Closing video source...");
            await videoSource.close();
            console.log("✓ Video source closed");

            // 6. Finalize and Export
            status.textContent = "Finalizing MP4 file...";
            console.log("Calling output.finalize()...");
            await output.finalize();
            console.log("✓ output.finalize() complete");

            // Debug: Check what's in the buffer
            console.log("=== OUTPUT BUFFER DEBUG ===");
            console.log("output.target:", output.target);
            console.log("output.target.buffer:", output.target.buffer);
            console.log("Buffer type:", output.target.buffer?.constructor?.name);
            console.log("Buffer byteLength:", output.target.buffer?.byteLength);
            console.log("Buffer length:", output.target.buffer?.length);

            let finalBlob;
            if (output.target.buffer instanceof ArrayBuffer) {
                console.log("Buffer is ArrayBuffer - creating Uint8Array wrapper");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else if (output.target.buffer instanceof Uint8Array) {
                console.log("Buffer is Uint8Array - using directly");
                finalBlob = new Blob([output.target.buffer], { type: 'video/mp4' });
            } else if (Array.isArray(output.target.buffer)) {
                console.log("Buffer is Array - converting to Uint8Array");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else {
                const bufferType = typeof output.target.buffer;
                console.error("Unknown buffer type:", bufferType);
                throw new Error(`Unexpected buffer type: ${bufferType}`);
            }

            console.log("✓ Final blob created - size:", finalBlob.size, "bytes");

            if (finalBlob.size < 200) {
                console.warn("⚠️  Blob is very small (likely just MP4 header, no video data encoded)");
            }

            document.getElementById('outputVideo').src = URL.createObjectURL(finalBlob);
            console.log("✓ Output video src set");

            status.textContent = "Success! Video generated locally.";
            processBtn.disabled = false;
            console.log("=== PIPELINE COMPLETE ===");
        }
    </script>
</body>
</html>