<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mediabunny Caption Burner - Final Prototype</title>
    <style>
        * { box-sizing: border-box; }
        body { font-family: -apple-system, system-ui, sans-serif; max-width: 900px; margin: 2rem auto; background: #0f172a; padding: 0 1rem; color: #e2e8f0; }
        .box { background: #1e293b; padding: 2.5rem; border-radius: 12px; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.5); text-align: center; border: 1px solid #334155; }
        .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 2rem; }
        video { width: 100%; border-radius: 8px; background: #000; border: 1px solid #334155; aspect-ratio: 16/9; }
        button { background: #2563eb; color: white; border: none; padding: 12px 24px; border-radius: 6px; cursor: pointer; font-size: 1rem; font-weight: 600; transition: all 0.2s; }
        button:hover { background: #1d4ed8; transform: translateY(-1px); }
        button:disabled { background: #475569; cursor: not-allowed; }
        input[type="text"], input[type="file"] { padding: 10px; width: 70%; margin: 15px 0; border: 1px solid #475569; border-radius: 6px; font-size: 1rem; text-align: center; background: #0f172a; color: #e2e8f0; }
        input[type="text"]:focus, input[type="file"]:focus { outline: none; border-color: #2563eb; box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.1); }
        #status { margin-top: 1.5rem; font-weight: 600; color: #94a3b8; min-height: 1.5em; }
        .loading-overlay { position: fixed; top:0; left:0; width:100%; height:100%; background: #0f172a; display: flex; justify-content: center; align-items: center; z-index: 100; flex-direction: column; }

        /* Tabs styling */
        .tabs-container { display: flex; gap: 0.5rem; margin-bottom: 2rem; border-bottom: 2px solid #334155; }
        .tab { padding: 12px 24px; background: none; border: none; cursor: pointer; color: #94a3b8; font-size: 1rem; font-weight: 600; border-bottom: 3px solid transparent; transition: all 0.2s; }
        .tab:hover { color: #cbd5e1; }
        .tab.active { color: #2563eb; border-bottom-color: #2563eb; }
        .tab-content { display: none; }
        .tab-content.active { display: block; }

        h1 { margin-top: 0; color: #f1f5f9; }
        p { color: #cbd5e1; }
        .info-text { font-size: 0.9rem; color: #94a3b8; margin: 0.5rem 0; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/hls.js@latest/dist/hls.min.js"></script>
</head>
<body>

    <div id="libLoading" class="loading-overlay">
        <h3>Loading Mediabunny...</h3>
        <p>Fetching modern media libraries from CDN</p>
    </div>

    <div class="box">
        <h1>üî• Video Caption Burner</h1>
        <p>Burn captions onto your videos. Works with files and HLS streams. Everything processes locally in your browser.</p>

        <div class="tabs-container">
            <button class="tab active" data-tab="file-tab">üìÅ Upload Video</button>
            <button class="tab" data-tab="hls-tab">üåê HLS Stream</button>
        </div>

        <div id="file-tab" class="tab-content active">
            <p class="info-text">Select an MP4 or WebM video file from your device</p>
            <input type="file" id="fileInput" accept="video/mp4,video/webm" /><br>
        </div>

        <div id="hls-tab" class="tab-content">
            <p class="info-text">Paste an HLS stream URL (must end with .m3u8)</p>
            <div style="display: flex; gap: 0.5rem; align-items: center; justify-content: center; margin: 15px 0;">
                <input type="text" id="hlsUrlInput" value="https://test-streams.mux.dev/x36xhzz/x36xhzz.m3u8" placeholder="https://example.com/video.m3u8" style="width: 50%; margin: 0;" />
                <button id="hlsLoadBtn" style="padding: 10px 20px; margin: 0;">Load</button>
            </div>
        </div>

        <input type="text" id="captionText" value="CAPTION" placeholder="Enter caption text"><br>
        <button id="processBtn" disabled>‚ö° Process & Burn Captions</button>
        <div id="status">Select a video to get started</div>
    </div>

    <div class="grid">
        <div>
            <h4>Original</h4>
            <video id="originalVideo" controls muted></video>
        </div>
        <div>
            <h4>Burned Result</h4>
            <video id="outputVideo" controls></video>
        </div>
    </div>

    <div id="shareButtons" style="display:none; text-align: center; margin-top: 2rem; gap: 1rem;">
        <button id="downloadBtn" style="background: #25d366; margin: 0 0.5rem;">‚¨áÔ∏è Download Video</button>
        <button id="whatsappBtn" style="background: #25d366; margin: 0 0.5rem;">üí¨ Share to WhatsApp</button>
    </div>

    <canvas id="canvas" style="display:none;"></canvas>

    <script type="module">
        import { 
            Output, 
            BufferTarget, 
            Mp4OutputFormat, 
            CanvasSource,
            VideoSampleSink,
            MediaStreamAudioTrackSource 
        } from 'https://esm.sh/mediabunny@1.25.8';

        // Remove loading screen once imports are ready
        document.getElementById('libLoading').style.display = 'none';

        const fileInput = document.getElementById('fileInput');
        const hlsUrlInput = document.getElementById('hlsUrlInput');
        const hlsLoadBtn = document.getElementById('hlsLoadBtn');
        const processBtn = document.getElementById('processBtn');
        const status = document.getElementById('status');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d', { alpha: false });
        const downloadBtn = document.getElementById('downloadBtn');
        const whatsappBtn = document.getElementById('whatsappBtn');
        const shareButtons = document.getElementById('shareButtons');

        let selectedFile = null;
        let hlsUrl = null;
        let sourceType = null; // 'file' or 'hls'
        let hlsInstance = null;
        let outputBlob = null;

        // Tab switching functionality
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                // Remove active class from all tabs and contents
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));

                // Add active class to clicked tab
                tab.classList.add('active');

                // Show corresponding content
                const tabId = tab.getAttribute('data-tab');
                document.getElementById(tabId).classList.add('active');

                // Clear the other input
                if (tabId === 'file-tab') {
                    hlsUrlInput.value = '';
                    hlsUrl = null;
                } else {
                    fileInput.value = '';
                    selectedFile = null;
                }
            });
        });

        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length) {
                selectedFile = e.target.files[0];
                hlsUrl = null; // Clear HLS URL when file is selected
                hlsUrlInput.value = ''; // Clear HLS input field
                sourceType = 'file';

                // Cleanup HLS instance if it exists
                if (hlsInstance) {
                    hlsInstance.destroy();
                    hlsInstance = null;
                }

                document.getElementById('originalVideo').src = URL.createObjectURL(selectedFile);
                processBtn.disabled = false;
                status.textContent = "Ready to process: " + selectedFile.name;
                console.log("File selected:", selectedFile.name);
            }
        });

        // Helper to load HLS URL
        async function loadHlsUrl(url) {
            url = url.trim();
            if (url) {
                // Validate URL format
                if (!url.match(/^https?:\/\/.+\.m3u8$/i)) {
                    status.textContent = "Invalid URL. Please provide a valid HLS stream URL ending with .m3u8";
                    hlsUrlInput.value = '';
                    processBtn.disabled = true;
                    return;
                }

                selectedFile = null; // Clear file when URL is entered
                fileInput.value = ''; // Clear file input field
                hlsUrl = url;
                sourceType = 'hls';

                status.textContent = "Loading HLS stream...";
                processBtn.disabled = true;

                try {
                    await loadHlsPreview(url);
                    processBtn.disabled = false;
                    status.textContent = "Ready to process: " + url;
                    console.log("HLS URL loaded:", url);
                } catch (err) {
                    console.error("HLS loading error:", err);
                    status.textContent = "Error loading HLS stream: " + err.message;
                    hlsUrl = null;
                    hlsUrlInput.value = '';
                    processBtn.disabled = true;
                }
            } else {
                selectedFile = null;
                hlsUrl = null;
                sourceType = null;
                processBtn.disabled = true;
                status.textContent = "Please select an MP4 file or HLS stream URL.";
            }
        }

        hlsUrlInput.addEventListener('change', async (e) => {
            await loadHlsUrl(e.target.value);
        });

        hlsLoadBtn.addEventListener('click', async () => {
            await loadHlsUrl(hlsUrlInput.value);
        });

        processBtn.addEventListener('click', async () => {
            processBtn.disabled = true;
            status.textContent = "Processing... do not close this tab.";

            console.log("=== PIPELINE START ===");
            try {
                const source = sourceType === 'file' ? selectedFile : hlsUrl;
                await runPipeline(sourceType, source, document.getElementById('captionText').value);
                console.log("=== PIPELINE SUCCESS ===");
            } catch (err) {
                console.error("=== PIPELINE ERROR ===", err);
                console.error("Error message:", err.message);
                console.error("Error stack:", err.stack);
                status.textContent = "Error: " + err.message;
                processBtn.disabled = false;
            }
        });

        // HLS helper function to load preview video
        async function loadHlsPreview(url) {
            const previewVideo = document.getElementById('originalVideo');

            // Check for native HLS support (Safari)
            if (previewVideo.canPlayType('application/vnd.apple.mpegurl')) {
                previewVideo.src = url;
                return new Promise((resolve) => {
                    previewVideo.addEventListener('loadedmetadata', resolve, { once: true });
                });
            }

            // Use hls.js for other browsers
            if (!window.Hls) {
                throw new Error('HLS.js library failed to load');
            }

            // Create new HLS instance for preview
            const tempHls = new Hls();
            tempHls.attachMedia(previewVideo);
            tempHls.loadSource(url);

            return new Promise((resolve, reject) => {
                tempHls.on(Hls.Events.MANIFEST_PARSED, () => {
                    resolve();
                });
                tempHls.on(Hls.Events.ERROR, (event, data) => {
                    tempHls.destroy();
                    reject(new Error(`HLS Error: ${data.type} - ${data.reason}`));
                });
            });
        }

        // HLS helper function to load source for processing
        async function loadHlsSource(url, videoElement) {
            // Check for native HLS support (Safari)
            if (videoElement.canPlayType('application/vnd.apple.mpegurl')) {
                videoElement.src = url;
                return new Promise((resolve, reject) => {
                    const timeout = setTimeout(() => reject(new Error('Metadata loading timeout')), 30000);
                    videoElement.addEventListener('loadedmetadata', () => {
                        clearTimeout(timeout);
                        resolve({
                            displayWidth: videoElement.videoWidth,
                            displayHeight: videoElement.videoHeight,
                            duration: videoElement.duration,
                            hlsInstance: null
                        });
                    }, { once: true });
                    videoElement.addEventListener('error', () => {
                        clearTimeout(timeout);
                        reject(videoElement.error);
                    }, { once: true });
                });
            }

            // Use hls.js for other browsers
            if (!window.Hls) {
                throw new Error('HLS.js library failed to load');
            }

            const hls = new Hls({
                enableWorker: true,
                lowLatencyMode: false
            });

            hls.attachMedia(videoElement);
            hls.loadSource(url);

            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    hls.destroy();
                    reject(new Error('HLS manifest loading timeout'));
                }, 30000);

                hls.on(Hls.Events.MANIFEST_PARSED, () => {
                    clearTimeout(timeout);
                    // Store instance for cleanup
                    hlsInstance = hls;
                    resolve({
                        displayWidth: videoElement.videoWidth,
                        displayHeight: videoElement.videoHeight,
                        duration: videoElement.duration,
                        hlsInstance: hls
                    });
                });

                hls.on(Hls.Events.ERROR, (event, data) => {
                    clearTimeout(timeout);
                    hls.destroy();
                    reject(new Error(`HLS Error: ${data.type} - ${data.reason}`));
                });
            });
        }

        // Helper function to wait for video metadata and get actual duration
        async function getVideoMetadata(videoElement) {
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('Video metadata loading timeout'));
                }, 10000);

                const onLoadedMetadata = () => {
                    clearTimeout(timeout);
                    videoElement.removeEventListener('loadedmetadata', onLoadedMetadata);
                    videoElement.removeEventListener('error', onError);

                    const actualDuration = videoElement.duration;
                    console.log("Video metadata loaded - duration:", actualDuration);

                    resolve({
                        width: videoElement.videoWidth,
                        height: videoElement.videoHeight,
                        duration: actualDuration
                    });
                };

                const onError = () => {
                    clearTimeout(timeout);
                    videoElement.removeEventListener('loadedmetadata', onLoadedMetadata);
                    videoElement.removeEventListener('error', onError);
                    reject(videoElement.error || new Error('Video loading error'));
                };

                videoElement.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });
                videoElement.addEventListener('error', onError, { once: true });
            });
        }

        async function runPipeline(sourceType, source, textToBurn) {
            // 1. Load metadata based on source type
            let displayWidth, displayHeight, duration, frameRate;
            let currentHlsInstance = null;
            let audioTrack = null; // Audio track reference

            const tempVideo = document.createElement('video');
            tempVideo.crossOrigin = 'anonymous';
            tempVideo.muted = false; // Important for audio capture
            tempVideo.volume = 0.0;  // Mute for user but keep active for capture (hopefully)

            if (sourceType === 'file') {
                console.log("Loading file source into video element...");
                tempVideo.src = URL.createObjectURL(source);

                // Wait for metadata
                const videoMeta = await getVideoMetadata(tempVideo);
                displayWidth = videoMeta.width;
                displayHeight = videoMeta.height;
                duration = videoMeta.duration;
                frameRate = 30; // Default to 30 as we can't easily read file FPS without parsing, or we could use VideoPlaybackQuality
                
                // Note: For files, we could assume 30 or try to detect. 
                // Since we are capturing playback, we are effectively resampling to whatever we drive the loop at.
                // We'll drive the loop at the video's natural pace (requestVideoFrameCallback).
                
            } else if (sourceType === 'hls') {
                console.log("Loading HLS source...");
                const metadata = await loadHlsSource(source, tempVideo);
                displayWidth = metadata.displayWidth;
                displayHeight = metadata.displayHeight;
                duration = metadata.duration || 10;
                frameRate = 30;
                currentHlsInstance = metadata.hlsInstance;

                if (!isFinite(duration) || duration <= 0) {
                    try {
                        const videoMeta = await getVideoMetadata(tempVideo);
                        duration = videoMeta.duration;
                    } catch (err) {
                        console.error("Failed to get duration:", err);
                        duration = 10;
                    }
                }
            } else {
                throw new Error('Unknown source type: ' + sourceType);
            }

            // Cap output duration at 30 seconds
            const MAX_OUTPUT_DURATION = 30;
            if (duration > MAX_OUTPUT_DURATION) {
                console.log(`Duration limited: ${duration.toFixed(2)}s ‚Üí ${MAX_OUTPUT_DURATION}s`);
                duration = MAX_OUTPUT_DURATION;
            }

            console.log("Video metadata:", { sourceType, displayWidth, displayHeight, duration: duration.toFixed(2) + 's' });

            // 2. Setup Canvas
            canvas.width = displayWidth;
            canvas.height = displayHeight;

            // Helper function for drawing
            function drawFrameAndBurn(vid, text, w, h) {
                ctx.drawImage(vid, 0, 0, w, h);
                const aspectRatio = w / h;
                const isVertical = aspectRatio < 1;
                const fontSize = isVertical ? h * 0.06 : h * 0.08;
                ctx.font = `bold ${Math.floor(fontSize)}px sans-serif`;
                ctx.fillStyle = '#ffffff';
                ctx.strokeStyle = '#000000';
                ctx.lineWidth = Math.max(2, h * 0.005);
                ctx.textAlign = 'center';
                const x = w / 2;
                const y = isVertical ? h - (h * 0.3) : h - (h * 0.1);
                ctx.strokeText(text, x, y);
                ctx.fillText(text, x, y);
            }

            // 3. Setup Audio (Unified via captureStream)
            try {
                console.log("Capturing stream from video element for audio...");
                // Note: For this to work with 'volume = 0.0', we rely on the browser implementing captureStream before volume gain.
                // If this results in silent audio, we might need to set volume=1 and use a muted audio context destination to hide it from user.
                const stream = tempVideo.captureStream ? tempVideo.captureStream() : tempVideo.mozCaptureStream();
                
                if (stream) {
                    const nativeAudioTrack = stream.getAudioTracks()[0];
                    if (nativeAudioTrack) {
                        audioTrack = new MediaStreamAudioTrackSource(nativeAudioTrack, {
                            codec: 'opus',
                            sampleRate: 48000,
                            numberOfChannels: 2,
                            bitrate: 128000
                        });
                        console.log("‚úì Captured audio track");
                    } else {
                        console.warn("Stream captured but no audio track found.");
                    }
                } else {
                    console.warn("captureStream not supported.");
                }
            } catch (err) {
                console.warn("Failed to capture audio stream:", err);
            }

            // 4. Setup Output
            const output = new Output({
                target: new BufferTarget(),
                format: new Mp4OutputFormat()
            });

            // 5. Setup Video Source
            const videoSource = new CanvasSource(canvas, {
                codec: 'avc',
                bitrate: 6_000_000
            });
            output.addVideoTrack(videoSource, { frameRate });

            if (audioTrack) {
                output.addAudioTrack(audioTrack);
            }

            await output.start();

            console.log("=== STARTING RECORDING (Play-Through) ===");

            // 7. Processing Loop (Unified Play-Through)
            let frameCount = 0;
            
            await new Promise((resolve, reject) => {
                let processing = true;
                
                const processFrame = async (now, metadata) => {
                    if (!processing) return;
                    
                    try {
                        // Check termination
                        if (tempVideo.ended || tempVideo.currentTime >= duration) {
                            console.log("Playback finished or duration reached.");
                            processing = false;
                            tempVideo.pause();
                            resolve();
                            return;
                        }

                        // Draw and Burn
                        drawFrameAndBurn(tempVideo, textToBurn, displayWidth, displayHeight);

                        // Add frame to encoder
                        // Use metadata.mediaTime if available (VideoFrameCallback), else fallback
                        // Note: metadata.mediaTime is the presentation time in seconds.
                        const timestamp = metadata.mediaTime;
                        // For duration, we can estimate based on frameRate or delta.
                        // CanvasSource expects explicit duration.
                        // Ideally we use (current - last) but '1/frameRate' is smooth enough for CFR output.
                        const frameDuration = 1 / frameRate; 
                        
                        await videoSource.add(timestamp, frameDuration);
                        frameCount++;
                        
                        if (frameCount % 30 === 0) {
                            status.textContent = `Recording: ${frameCount} frames...`;
                        }

                        // Continue
                        tempVideo.requestVideoFrameCallback(processFrame);
                    } catch (e) {
                        processing = false;
                        reject(e);
                    }
                };

                // Start playback
                // Ensure we catch the first frame
                tempVideo.requestVideoFrameCallback(processFrame);
                
                tempVideo.play().catch(e => {
                    console.error("Auto-play failed:", e);
                    reject(e);
                });
            });

            console.log("=== RECORDING COMPLETE ===");
            console.log("Total frames encoded:", frameCount);

            console.log("Closing video source...");
            await videoSource.close();
            console.log("‚úì Video source closed");

            status.textContent = "Finalizing MP4 file...";
            console.log("Calling output.finalize()...");
            await output.finalize();
            console.log("‚úì output.finalize() complete");

            // Debug: Check what's in the buffer
            console.log("=== OUTPUT BUFFER DEBUG ===");
            console.log("output.target:", output.target);
            console.log("output.target.buffer:", output.target.buffer);
            console.log("Buffer type:", output.target.buffer?.constructor?.name);
            console.log("Buffer byteLength:", output.target.buffer?.byteLength);
            console.log("Buffer length:", output.target.buffer?.length);

            let finalBlob;
            if (output.target.buffer instanceof ArrayBuffer) {
                console.log("Buffer is ArrayBuffer - creating Uint8Array wrapper");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else if (output.target.buffer instanceof Uint8Array) {
                console.log("Buffer is Uint8Array - using directly");
                finalBlob = new Blob([output.target.buffer], { type: 'video/mp4' });
            } else if (Array.isArray(output.target.buffer)) {
                console.log("Buffer is Array - converting to Uint8Array");
                finalBlob = new Blob([new Uint8Array(output.target.buffer)], { type: 'video/mp4' });
            } else {
                const bufferType = typeof output.target.buffer;
                console.error("Unknown buffer type:", bufferType);
                throw new Error(`Unexpected buffer type: ${bufferType}`);
            }

            console.log("‚úì Final blob created - size:", finalBlob.size, "bytes");

            if (finalBlob.size < 200) {
                console.warn("‚ö†Ô∏è  Blob is very small (likely just MP4 header, no video data encoded)");
            }

            const videoUrl = URL.createObjectURL(finalBlob);
            document.getElementById('outputVideo').src = videoUrl;
            console.log("‚úì Output video src set");

            // Store blob for sharing and downloading
            outputBlob = finalBlob;
            shareButtons.style.display = 'flex';

            status.textContent = "Success! Video generated locally. Share or download below.";
            processBtn.disabled = false;

            // Cleanup HLS instance if used
            if (currentHlsInstance) {
                console.log("Cleaning up HLS instance...");
                currentHlsInstance.destroy();
                hlsInstance = null;
            }

            console.log("=== PIPELINE COMPLETE ===");
        }

        // Download button handler
        downloadBtn.addEventListener('click', () => {
            if (!outputBlob) return;
            const url = URL.createObjectURL(outputBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `caption-burn-${new Date().getTime()}.mp4`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            console.log("‚úì Video downloaded");
        });

        // WhatsApp share button handler
        whatsappBtn.addEventListener('click', async () => {
            if (!outputBlob) return;

            const videoFile = new File([outputBlob], 'caption-burn-video.mp4', { type: 'video/mp4' });

            // Check if Web Share API is available (for mobile)
            if (navigator.share && navigator.canShare) {
                try {
                    // Test if files can be shared
                    if (navigator.canShare({ files: [videoFile] })) {
                        await navigator.share({
                            files: [videoFile],
                            title: 'Caption Burned Video',
                            text: 'Check out this video with burned-in captions!'
                        });
                        console.log("‚úì Shared via Web Share API");
                        status.textContent = "Video shared to WhatsApp!";
                    } else {
                        // Files not supported, use text-only fallback
                        throw new Error('File sharing not supported');
                    }
                } catch (err) {
                    console.log("Web Share API not available or failed, using WhatsApp Web fallback");
                    // Fallback: Open WhatsApp Web with a message
                    const text = "Check out this video with burned-in captions! Generated with Caption Burner üî•";
                    const whatsappUrl = `https://wa.me/?text=${encodeURIComponent(text)}`;
                    window.open(whatsappUrl, '_blank');
                    console.log("‚úì Opened WhatsApp Web");
                    status.textContent = "WhatsApp Web opened! Download the video and attach it to your message.";
                }
            } else {
                // Fallback: Open WhatsApp Web with a message
                const text = "Check out this video with burned-in captions! Generated with Caption Burner üî•";
                const whatsappUrl = `https://wa.me/?text=${encodeURIComponent(text)}`;
                window.open(whatsappUrl, '_blank');
                console.log("‚úì Opened WhatsApp Web");

                // Show instructions
                status.textContent = "WhatsApp Web opened! Download the video and attach it to your message.";
            }
        });
    </script>
</body>
</html>